{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSA(잠재의미분석)",
      "provenance": [],
      "authorship_tag": "ABX9TyOpxkf+MFcc6ttgqnSBEKqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2020-nlp-c/nlp-statisticsmodel/blob/master/Sojeong_Cho/LSA(%EC%9E%A0%EC%9E%AC%EC%9D%98%EB%AF%B8%EB%B6%84%EC%84%9D).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sEaCv-VB1bL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "7d8cccbd-cfe5-4e52-9e95-765d27c9f955"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import randomized_svd\n",
        "\n",
        "class  LSA() :\n",
        "    def __init__(self) :\n",
        "        pass\n",
        "\n",
        "    def _make_dtm(self) :#언더바를 쓴것은 외부에서 호출하지 않겠다는 뜻\n",
        "\n",
        "        def tokenize(x):\n",
        "            return x.split()\n",
        "        \n",
        "        cv = CountVectorizer(tokenizer = tokenize)\n",
        "        self.DTM = cv.fit_transform(self.docs).toarray()\n",
        "        self.feature_names = cv.get_feature_names()\n",
        "        self.word2id = cv.vocabulary_\n",
        "    \n",
        "    def _truncatedSVD(self) :\n",
        "\n",
        "        self.U, s, self.VT = randomized_svd(self.DTM, n_components=self.k, n_iter = 10) #특이값분해\n",
        "\n",
        "    def print_topics(self) :#언더바를 쓰지 않은 것은 외부에서도 호출하겠다는 뜻\n",
        "        for topic in self.VT :\n",
        "            print([self.feature_names[i] for i in topic.argsort()[::-1][:self.n_words]])\n",
        "\n",
        "    def get_word_vec(self, keyword) :\n",
        "        v = self.VT.T[self.word2id[keyword]]\n",
        "        print(\"단어 {} : {}\".format(keyword, v))\n",
        "        return v\n",
        "\n",
        "    def get_doc_vec(self, idx_doc) :\n",
        "        v = self.U[idx_doc]\n",
        "        print(\"문서 {} : {}\".format(idx_doc, v))\n",
        "        return v\n",
        "\n",
        "    def calc_similarity(self, x, y) :# x와 y, 두 벡터의 코사인 유사도를 계산하는 함수\n",
        "        nominator = np.dot(x, y)    # 분자\n",
        "        denominator = np.linalg.norm(x)*np.linalg.norm(y)  # 분모\n",
        "        print('유사도 : {}'.format(nominator/denominator))\n",
        "        return nominator/denominator\n",
        "\n",
        "    def train(self, docs, k, n_words = 3) :\n",
        "        self.docs = docs\n",
        "        self.k = k\n",
        "        self.n_words = n_words\n",
        "\n",
        "        self._make_dtm()\n",
        "        self._truncatedSVD()\n",
        "        self.print_topics()\n",
        "\n",
        "\n",
        "    def search(self, keyword, n_docs = 5) :\n",
        "        wv = self.get_word_vec(keyword)\n",
        "        print([self.feature_names[i] for i in np.dot(wv, self.U.T).argsort()[::-1][:n_docs]])\n",
        "\n",
        "if __name__ == '__main__' :#시작점 확인\n",
        "    doc_ls = ['바나나 사과 포도 포도 짜장면',\n",
        "         '사과 포도',\n",
        "         '포도 바나나',\n",
        "         '짜장면 짬뽕 탕수육',\n",
        "         '볶음밥 탕수육',\n",
        "         '짜장면 짬뽕',\n",
        "         '라면 스시',\n",
        "         '스시 짜장면',\n",
        "         '가츠동 스시 소바',\n",
        "         '된장찌개 김치찌개 김치',\n",
        "         '김치 된장 짜장면',\n",
        "         '비빔밥 김치'\n",
        "         ]\n",
        "\n",
        "    lsa = LSA()\n",
        "    lsa.train(doc_ls, k=4, n_words=3)\n",
        "\n",
        "    lsa.get_doc_vec(1)\n",
        "    lsa.get_word_vec(\"라면\")\n",
        "    lsa.calc_similarity(lsa.get_doc_vec(1), lsa.get_word_vec(\"라면\"))\n",
        "    lsa.calc_similarity(lsa.get_word_vec(\"포도\"), lsa.get_word_vec(\"사과\"))\n",
        "\n",
        "    lsa.calc_similarity(lsa.get_doc_vec(1), lsa.get_word_vec('바나나'))\n",
        "    lsa.search(\"비빔밥\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['포도', '짜장면', '바나나']\n",
            "['짜장면', '짬뽕', '김치']\n",
            "['김치', '된장찌개', '김치찌개']\n",
            "['스시', '김치', '소바']\n",
            "문서 1 : [ 0.32422891 -0.2375544   0.02301229  0.05619723]\n",
            "단어 라면 : [ 0.00733397  0.05136218 -0.15788435  0.18435345]\n",
            "문서 1 : [ 0.32422891 -0.2375544   0.02301229  0.05619723]\n",
            "단어 라면 : [ 0.00733397  0.05136218 -0.15788435  0.18435345]\n",
            "유사도 : -0.030690640313503915\n",
            "단어 포도 : [ 0.69686254 -0.38741921  0.03185185  0.07489549]\n",
            "단어 사과 : [ 0.34843127 -0.19370961  0.01592593  0.03744775]\n",
            "유사도 : 1.0\n",
            "문서 1 : [ 0.32422891 -0.2375544   0.02301229  0.05619723]\n",
            "단어 바나나 : [ 0.34843127 -0.19370961  0.01592593  0.03744775]\n",
            "유사도 : 0.9911706701023305\n",
            "단어 비빔밥 : [0.00823912 0.06761161 0.18453253 0.12393905]\n",
            "['사과', '스시', '소바', '김치', '김치찌개']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}