{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBC_조소정",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWMzuLHfZkYTQAEYuuSemC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2020-nlp-c/nlp-statisticsmodel/blob/master/Sojeong_Cho/NBC_%EC%A1%B0%EC%86%8C%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqMzM9tCCzTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "os.chdir(\"C:\\\\Users\\\\sojeo\\\\SJ_practice\")\n",
        "\n",
        "# Document Classifier\n",
        "class NaiveBayesClassifier() :\n",
        "    def __init__(self) :\n",
        "        pass\n",
        "    def _tokenize(self, docs) :\n",
        "        return [d.split() for d in docs]\n",
        "\n",
        "    # 사전확률, 우도 학습\n",
        "    def train(self, docs, labels, k = 0.5, model='nbc.model'):\n",
        "\n",
        "        #label별 인덱스 지정\n",
        "        label2i = {k:i for i, k in enumerate(np.unique(labels))}\n",
        "        self.i2label = {i:k for k, i in label2i.items()}\n",
        "        label_prob = np.zeros(len(label2i))\n",
        "        tokenized_docs = self._tokenize(docs)\n",
        "\n",
        "        #label별 빈도 계산\n",
        "        nbc_dic = {}\n",
        "        for i, doc in enumerate(tokenized_docs) :\n",
        "            for w in doc :\n",
        "                if w in nbc_dic.keys() :\n",
        "                    nbc_dic[w]['count'][label2i[labels[i]]] += 1\n",
        "                else :\n",
        "                    nbc_dic[w] = {'count' : np.zeros(len(label2i)), 'prob' : np.zeros(len(label2i)), 'log_prob' : np.zeros(len(label2i)) }\n",
        "                    nbc_dic[w]['count'][label2i[labels[i]]] = 1\n",
        "                label_prob[label2i[labels[i]]] += 1\n",
        "\n",
        "        #확률 계산\n",
        "        for w in nbc_dic.keys() :\n",
        "            for label in label2i.keys() :\n",
        "                nbc_dic[w]['prob'][label2i[label]] = (k + nbc_dic[w]['count'][label2i[label]]) / (2*k + label_prob[label2i[label]])\n",
        "                nbc_dic[w]['log_prob'][label2i[label]] = np.log(nbc_dic[w]['prob'][label2i[label]] )\n",
        "\n",
        "        self.nbc_dic = nbc_dic\n",
        "        self.label2i = label2i\n",
        "        self.label_prob = np.log(label_prob/label_prob.sum())\n",
        "\n",
        "        with open(model, 'wb') as f :\n",
        "            tmp = {'label_prob' : label_prob\n",
        "            , 'nbc_dic' : self.nbc_dic\n",
        "            , 'i2label' : self.i2label\n",
        "            , 'label2i' : self.label2i}\n",
        "            pickle.dump(tmp, f)\n",
        "\n",
        "    # 새로운 문서 분류\n",
        "    def predict(self, docs, model = None):\n",
        "        if model :\n",
        "            with open(model, 'rb') as f :\n",
        "                tmp = pickle.load(f)\n",
        "                self.label_prob = tmp['label_prob']\n",
        "                self.nbc_dic = tmp['nbc_dic']\n",
        "                self.i2label = tmp['i2label']\n",
        "                self.label2i = tmp['label2i']\n",
        "\n",
        "        tokenized_docs = self._tokenize(docs)\n",
        "        results = []\n",
        "\n",
        "        #라벨별 확률\n",
        "        for d in tokenized_docs :\n",
        "            prob_for_label = np.zeros(len(self.label2i))\n",
        "\n",
        "            for w in d :\n",
        "                for label, i in self.label2i.items() :\n",
        "                    prob_for_label[i] += self.nbc_dic[w]['log_prob'][i]\n",
        "            tmp = np.exp(prob_for_label + self.label_prob)\n",
        "            prob = tmp / tmp.sum()\n",
        "\n",
        "            results.append(self.i2label[prob.argsort()[::-1][0]])\n",
        "        return results\n",
        "\n",
        "    # 정확도 측정\n",
        "    def score(self, docs, labels, model = None):\n",
        "        predictions = self.predict(docs, model)\n",
        "        return np.mean(np.array(predictions) == np.array(labels))\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    df_train = pd.read_csv(\"train.csv\")\n",
        "    df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "    X_train, Y_train = df_train['mail'].tolist(), df_train['label'].tolist()\n",
        "    X_test, Y_test = df_test['mail'].tolist(), df_test['label'].tolist()\n",
        "\n",
        "    nbc = NaiveBayesClassifier()\n",
        "    # nbc.train(X_train, Y_train)\n",
        "    #nbc.predict(X_test)\n",
        "    print(nbc.score(X_test, Y_test, model = 'nbc.model'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}