{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Topic_modelinf(LDA) 직접구현.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW13flpUktUbNsY99H833e"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TH_sP8gvrUwv","colab_type":"text"},"source":["#Topic_modeling(LDA) 직접 구현"]},{"cell_type":"markdown","metadata":{"id":"re80DwGmrcDx","colab_type":"text"},"source":["###문서 정의(문장 구분 포함)\n"]},{"cell_type":"code","metadata":{"id":"4p957h6vVaDk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681400657,"user_tz":-540,"elapsed":1479,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["docs = ['cute kitty',\n","          'eat rice cake',\n","          'kitty hamster',\n","          'eat bread',\n","          'rice bread cake',\n","          'cute hamster eat bread cake']\n","        "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKyCrYSsrgrm","colab_type":"text"},"source":["###토큰화"]},{"cell_type":"code","metadata":{"id":"x9BSsJkTV5XE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1596681402470,"user_tz":-540,"elapsed":3282,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"60e968ca-fc8e-4a19-891f-9d4eb04d874e"},"source":["doc_ls = [doc.split() for doc in docs]\n","doc_ls"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['cute', 'kitty'],\n"," ['eat', 'rice', 'cake'],\n"," ['kitty', 'hamster'],\n"," ['eat', 'bread'],\n"," ['rice', 'bread', 'cake'],\n"," ['cute', 'hamster', 'eat', 'bread', 'cake']]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"wr-dnM0qrvhB","colab_type":"text"},"source":["###토큰 인덱싱 딕셔너리 생성\n"]},{"cell_type":"code","metadata":{"id":"ft-jiFLuWTgo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681402471,"user_tz":-540,"elapsed":3280,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["# 토큰의 인덱스 생성\n","def word2id(doc_ls) :\n","    from collections import defaultdict\n","\n","    word2id = defaultdict(lambda : len(word2id))\n","    [word2id[token] for doc in doc_ls for token in doc ]     \n","\n","    return word2id\n","\n","# 토큰의 인덱스를 키로 갖는 사전 생성\n","def id2word(word2id) :\n","\n","    id2word ={}\n","    for k,v in word2id.items():\n","        id2word[v] = k\n","    return id2word"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"42OdvNluWk2N","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681402471,"user_tz":-540,"elapsed":3277,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["word2idx = word2id(doc_ls)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYoyD1Y6WooT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681402472,"user_tz":-540,"elapsed":3275,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["idex2word = id2word(word2idx)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0dZ8FVHW-kg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1596681402473,"user_tz":-540,"elapsed":3270,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"38997716-4da7-446f-aadc-5ae214a00eb7"},"source":["word2idx"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(<function __main__.word2id.<locals>.<lambda>>,\n","            {'bread': 6,\n","             'cake': 4,\n","             'cute': 0,\n","             'eat': 2,\n","             'hamster': 5,\n","             'kitty': 1,\n","             'rice': 3})"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"hJqGC3tqXCjJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1596681402473,"user_tz":-540,"elapsed":3261,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"16fbef0f-de3b-4a8d-be2f-3a91e307ae58"},"source":["idex2word"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'cute',\n"," 1: 'kitty',\n"," 2: 'eat',\n"," 3: 'rice',\n"," 4: 'cake',\n"," 5: 'hamster',\n"," 6: 'bread'}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"jTru1vwGsFcZ","colab_type":"text"},"source":["###각 단어에 랜덤하게 토픽 할당(토픽 개수 임의 지정)"]},{"cell_type":"code","metadata":{"id":"ZdT13y4TXD4w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596681402474,"user_tz":-540,"elapsed":3252,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"dba59575-78fc-4113-9bdd-e0ee517c3c5c"},"source":["import random\n","\n","# 토픽의 개수를 정한뒤, 각 단어에 랜덤하게 토픽 할당\n","topic_num = 2\n","\n","# 2차원 리스트 그대로 쓰자\n","# doc_ls와 같은 모양의 리스트 생성\n","\n","topic_ls = []\n","\n","for doc_idx in range(len(doc_ls)) :\n","    temp_ls = []\n","    for i in range(len(doc_ls[doc_idx])):\n","        temp_ls.append(random.randint(1,topic_num))\n","    topic_ls.append(temp_ls)\n","\n","topic_ls\n","\n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2], [1, 2, 2], [1, 2], [1, 1], [2, 1, 1], [2, 2, 2, 2, 2]]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"oby1UctlsXZC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681402475,"user_tz":-540,"elapsed":3250,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":[""],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ed-jZrfosW7F","colab_type":"text"},"source":["###문서별 토픽 분포 표 작성"]},{"cell_type":"code","metadata":{"id":"inRsYke-cxey","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596681402476,"user_tz":-540,"elapsed":3245,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"40b1cc56-df45-4190-be8e-931ecfad0f0d"},"source":["import numpy as np\n","topic_dist_matrix_doc = np.ones((topic_num, len(doc_ls))) *0.1 #행: 토픽 수, 열 : 문서 수 //0.1은 a\n","\n","#문서별 토픽 분포 확인하고 topic_dist_matrix에 반영해주기\n","for idx, doc in enumerate(topic_ls):\n","    for word_topic in doc :\n","        topic_dist_matrix_doc[word_topic-1][idx] += 1\n","topic_dist_matrix_doc\n"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.1, 1.1, 1.1, 2.1, 2.1, 0.1],\n","       [1.1, 2.1, 1.1, 0.1, 1.1, 5.1]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Fefku_IasemF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1596681402476,"user_tz":-540,"elapsed":3237,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"c620c7df-93b9-4bae-9110-b725df68b9c8"},"source":["import pandas as pd\n","\n","matrix_doc = pd.DataFrame(topic_dist_matrix_doc,columns=['문서 {}'.format(i) for i in range(len(doc_ls))], index= ['topic {}'.format(j+1) for j in range(topic_num)])\n","matrix_doc"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>문서 0</th>\n","      <th>문서 1</th>\n","      <th>문서 2</th>\n","      <th>문서 3</th>\n","      <th>문서 4</th>\n","      <th>문서 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic 1</th>\n","      <td>1.1</td>\n","      <td>1.1</td>\n","      <td>1.1</td>\n","      <td>2.1</td>\n","      <td>2.1</td>\n","      <td>0.1</td>\n","    </tr>\n","    <tr>\n","      <th>topic 2</th>\n","      <td>1.1</td>\n","      <td>2.1</td>\n","      <td>1.1</td>\n","      <td>0.1</td>\n","      <td>1.1</td>\n","      <td>5.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         문서 0  문서 1  문서 2  문서 3  문서 4  문서 5\n","topic 1   1.1   1.1   1.1   2.1   2.1   0.1\n","topic 2   1.1   2.1   1.1   0.1   1.1   5.1"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"TDDqPaGXty9X","colab_type":"text"},"source":["###토픽 내 단어 분포 매트릭스"]},{"cell_type":"code","metadata":{"id":"VsPmsQzdikSa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596681402477,"user_tz":-540,"elapsed":3230,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"0224f50e-c920-4688-8945-0a9db620405e"},"source":["#토픽 내 단어 분포 표 초기화\n","topic_dist_matrix_word = np.ones((topic_num, len(word2idx))) *0.001 #행: 토픽 수, 열 : 유니크 토큰 수    0.01은 b\n","\n","#토픽 내 단어 분포 표 # 각 위치에 해당하는 토픽을 받고 doc_ls\n","for idx, doc in enumerate(topic_ls):\n","    for idx2, word_topic in enumerate(doc) :\n","        topic_dist_matrix_word[word_topic-1][word2idx[doc_ls[idx][idx2]]] += 1 # doc_ls[idx][idx2]는 해당 토픽이 배정된 단어\n","print(word2idx)\n","print(topic_dist_matrix_word)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["defaultdict(<function word2id.<locals>.<lambda> at 0x7f29afd566a8>, {'cute': 0, 'kitty': 1, 'eat': 2, 'rice': 3, 'cake': 4, 'hamster': 5, 'bread': 6})\n","[[1.001e+00 1.001e+00 2.001e+00 1.000e-03 1.001e+00 1.000e-03 2.001e+00]\n"," [1.001e+00 1.001e+00 1.001e+00 2.001e+00 2.001e+00 2.001e+00 1.001e+00]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iuz33tjst876","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1596681402478,"user_tz":-540,"elapsed":3224,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"9210e07f-cdf4-43d4-d080-6fb6c0bd9b75"},"source":["import pandas as pd\n","\n","matrix_word = pd.DataFrame(topic_dist_matrix_word,columns=[i for i in word2idx.keys()], index= ['topic {}'.format(j+1) for j in range(topic_num)])\n","matrix_word"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cute</th>\n","      <th>kitty</th>\n","      <th>eat</th>\n","      <th>rice</th>\n","      <th>cake</th>\n","      <th>hamster</th>\n","      <th>bread</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic 1</th>\n","      <td>1.001</td>\n","      <td>1.001</td>\n","      <td>2.001</td>\n","      <td>0.001</td>\n","      <td>1.001</td>\n","      <td>0.001</td>\n","      <td>2.001</td>\n","    </tr>\n","    <tr>\n","      <th>topic 2</th>\n","      <td>1.001</td>\n","      <td>1.001</td>\n","      <td>1.001</td>\n","      <td>2.001</td>\n","      <td>2.001</td>\n","      <td>2.001</td>\n","      <td>1.001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          cute  kitty    eat   rice   cake  hamster  bread\n","topic 1  1.001  1.001  2.001  0.001  1.001    0.001  2.001\n","topic 2  1.001  1.001  1.001  2.001  2.001    2.001  1.001"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"vVfIiuRMkOQp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596681402479,"user_tz":-540,"elapsed":3217,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"60ae06ea-6ce2-4d0f-88cd-cdca384898ce"},"source":["# 문서A 내에 topic 1이 있을 확률\n","\n","#문서 내 토픽 합계 리스트\n","topic_sum_ls = []\n","for j in range(len(doc_ls)) :\n","    temp_sum = 0\n","    for i in range(topic_num) :\n","        temp_sum += topic_dist_matrix_doc[i][j]\n","    topic_sum_ls.append(temp_sum)\n","topic_sum_ls"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2.2, 3.2, 2.2, 2.2, 3.2, 5.199999999999999]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"Np2sKCcMu4Kd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1596681402480,"user_tz":-540,"elapsed":3210,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"1ed3dcf2-a269-4606-efcb-11e98c654abb"},"source":["matrix_doc.loc['합계'] = topic_sum_ls\n","matrix_doc"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>문서 0</th>\n","      <th>문서 1</th>\n","      <th>문서 2</th>\n","      <th>문서 3</th>\n","      <th>문서 4</th>\n","      <th>문서 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic 1</th>\n","      <td>1.1</td>\n","      <td>1.1</td>\n","      <td>1.1</td>\n","      <td>2.1</td>\n","      <td>2.1</td>\n","      <td>0.1</td>\n","    </tr>\n","    <tr>\n","      <th>topic 2</th>\n","      <td>1.1</td>\n","      <td>2.1</td>\n","      <td>1.1</td>\n","      <td>0.1</td>\n","      <td>1.1</td>\n","      <td>5.1</td>\n","    </tr>\n","    <tr>\n","      <th>합계</th>\n","      <td>2.2</td>\n","      <td>3.2</td>\n","      <td>2.2</td>\n","      <td>2.2</td>\n","      <td>3.2</td>\n","      <td>5.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         문서 0  문서 1  문서 2  문서 3  문서 4  문서 5\n","topic 1   1.1   1.1   1.1   2.1   2.1   0.1\n","topic 2   1.1   2.1   1.1   0.1   1.1   5.1\n","합계        2.2   3.2   2.2   2.2   3.2   5.2"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"7IvT9GyDxaBx","colab_type":"text"},"source":["###문서 내 토픽이 있을 확률"]},{"cell_type":"code","metadata":{"id":"ogxWujKem9aS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1596681402480,"user_tz":-540,"elapsed":3202,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"110b50b9-2bdf-4eee-c1f5-701433128334"},"source":["# 문서 내에 토픽이 있을 확률을 나타내는 새로운 매트릭스 생성\n","topic_in_doc_matrix = np.zeros((topic_num, len(doc_ls)))\n","\n","for i in range(topic_num) :\n","    for j in range(len(doc_ls)) :\n","        topic_in_doc_matrix[i][j] = topic_dist_matrix_doc[i][j]/topic_sum_ls[j]\n","        # topic_in_doc_matrix[i][j] = 0.001/topic_sum_ls[j]\n","topic_in_doc_matrix\n","pd.DataFrame(topic_in_doc_matrix,columns=['문서 {}'.format(i) for i in range(len(doc_ls))], index= ['topic {}'.format(j+1) for j in range(topic_num)])"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>문서 0</th>\n","      <th>문서 1</th>\n","      <th>문서 2</th>\n","      <th>문서 3</th>\n","      <th>문서 4</th>\n","      <th>문서 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic 1</th>\n","      <td>0.5</td>\n","      <td>0.34375</td>\n","      <td>0.5</td>\n","      <td>0.954545</td>\n","      <td>0.65625</td>\n","      <td>0.019231</td>\n","    </tr>\n","    <tr>\n","      <th>topic 2</th>\n","      <td>0.5</td>\n","      <td>0.65625</td>\n","      <td>0.5</td>\n","      <td>0.045455</td>\n","      <td>0.34375</td>\n","      <td>0.980769</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         문서 0     문서 1  문서 2      문서 3     문서 4      문서 5\n","topic 1   0.5  0.34375   0.5  0.954545  0.65625  0.019231\n","topic 2   0.5  0.65625   0.5  0.045455  0.34375  0.980769"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"MGG4BSF_zXtz","colab_type":"text"},"source":["###토픽 내의 단어가 특정 단어일 확률"]},{"cell_type":"code","metadata":{"id":"85xSE49Hoc04","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1596681402481,"user_tz":-540,"elapsed":3196,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"cd20d8f8-3abc-4126-b26d-718291dc8ede"},"source":["word_in_topic_matrix = np.zeros((topic_num, len(word2idx)))\n","\n","for idx, topic in enumerate(topic_dist_matrix_word) :\n","    for idx2, topic_word in enumerate(topic) :\n","        word_in_topic_matrix[idx][idx2] = topic_word/sum(topic)\n","word_in_topic_matrix\n","pd.DataFrame(word_in_topic_matrix, columns= word2idx.keys(), index= ['topic {}'.format(j+1) for j in range(topic_num)])"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cute</th>\n","      <th>kitty</th>\n","      <th>eat</th>\n","      <th>rice</th>\n","      <th>cake</th>\n","      <th>hamster</th>\n","      <th>bread</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic 1</th>\n","      <td>0.142857</td>\n","      <td>0.142857</td>\n","      <td>0.285572</td>\n","      <td>0.000143</td>\n","      <td>0.142857</td>\n","      <td>0.000143</td>\n","      <td>0.285572</td>\n","    </tr>\n","    <tr>\n","      <th>topic 2</th>\n","      <td>0.100030</td>\n","      <td>0.100030</td>\n","      <td>0.100030</td>\n","      <td>0.199960</td>\n","      <td>0.199960</td>\n","      <td>0.199960</td>\n","      <td>0.100030</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             cute     kitty       eat      rice      cake   hamster     bread\n","topic 1  0.142857  0.142857  0.285572  0.000143  0.142857  0.000143  0.285572\n","topic 2  0.100030  0.100030  0.100030  0.199960  0.199960  0.199960  0.100030"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"bvjKww5Nz77c","colab_type":"text"},"source":["###토픽 할당"]},{"cell_type":"code","metadata":{"id":"XaMxEzKC7Xnj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596681520547,"user_tz":-540,"elapsed":901,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"94fe06c6-2003-4ed8-f6f5-7a37532bcb18"},"source":["#단어마다 토픽을 할당해주기 위해 doc_ls와 같은 형식의 topic_distribution_ls 초기화\n","topic_distribution_ls = [[0 for x in range(len(topic_ls[i]))] for i in range(len(topic_ls))]\n","\n","#문서 안의 특정 단어가 토픽 1일 확률\n","#doc_ls a문서의 첫번째 단어가 토픽 1일 확률, 토픽 2일 확률을 비교해 큰값 doc_ls 형태에 반영\n","for idx, doc in enumerate(topic_ls):\n","    for idx2, word_topic in enumerate(doc) :\n","        topic_dist_matrix_word[word_topic-1][word2idx[doc_ls[idx][idx2]]] += 1\n","\n","compare_list = [] \n","for idx, doc in enumerate(doc_ls) : #문서 인덱스 가져오기\n","    for idx2, word_topic in enumerate(doc) :\n","        temp_list = []\n","        for i in range(topic_num) :\n","            temp_list.append(topic_in_doc_matrix[i][idx] * word_in_topic_matrix[i][word2idx[doc_ls[idx][idx2]]])   #토픽 1일 확률과 토픽 2일 확률 비교\n","        compare_list.append(temp_list)\n","\n","        # compare_list[idx].argsort()\n","        topic_distribution_ls[idx][idx2] = np.array(compare_list[idx]).argsort()[0] + 1 # topic 분류를 위해 1 더함\n","\n","# print(compare_list)\n","# print()\n","# print(topic_distribution_ls)\n","topic_distribution_ls\n"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[2, 2], [2, 2, 2], [2, 2], [1, 1], [1, 1, 1], [2, 2, 2, 2, 2]]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"6CBgyEn0BMMn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681523239,"user_tz":-540,"elapsed":873,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["#topic_distribution_ls 을 topic_ls에 넣고 다시 전체 반복 "],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMwV-pW6EaC8","colab_type":"text"},"source":["###함수화"]},{"cell_type":"code","metadata":{"id":"pzpkpeDZEXVL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596681527902,"user_tz":-540,"elapsed":960,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":["class LDA :\n","    def __init__(self, topic_num, doc_ls) :\n","        self.doc_ls = doc_ls\n","        self.topic_num = topic_num\n","\n","    def word2id(self) :\n","        from collections import defaultdict\n","\n","        word2id = defaultdict(lambda : len(word2id))\n","        [word2id[token] for doc in self.doc_ls for token in doc ]     \n","\n","        return word2id\n","\n","    # 토큰의 인덱스를 키로 갖는 사전 생성\n","    def id2word(word2id) :\n","\n","        id2word ={}\n","        for k,v in word2id.items():\n","            id2word[v] = k\n","        return id2word\n","\n","    def mk_topic_dist_matrix(self, topic_ls) :\n","        import numpy as np\n","        topic_dist_matrix_doc = np.ones((self.topic_num, len(self.doc_ls))) *0.1 #행: 토픽 수, 열 : 문서 수 //0.1은 a\n","\n","        #문서별 토픽 분포 확인하고 topic_dist_matrix에 반영해주기\n","        for idx, doc in enumerate(topic_ls):\n","            for word_topic in doc :\n","                topic_dist_matrix_doc[word_topic-1][idx] += 1\n","        return topic_dist_matrix_doc\n","\n","    def mk_topic_dist_matrix_word(self, topic_ls, word2idx) :\n","        #토픽 내 단어 분포 표 초기화\n","        topic_dist_matrix_word = np.ones((self.topic_num, len(word2idx))) *0.001 #행: 토픽 수, 열 : 유니크 토큰 수    0.01은 b\n","\n","        #토픽 내 단어 분포 표 # 각 위치에 해당하는 토픽을 받고 doc_ls\n","        for idx, doc in enumerate(topic_ls):\n","            for idx2, word_topic in enumerate(doc) :\n","                topic_dist_matrix_word[word_topic-1][word2idx[self.doc_ls[idx][idx2]]] += 1 # doc_ls[idx][idx2]는 해당 토픽이 배정된 단어\n","\n","        return topic_dist_matrix_word\n","\n","    def chance_topic_in_doc(self, topic_dist_matrix_doc) :\n","        # 문서A 내에 topic 1이 있을 확률\n","\n","        #문서 내 토픽 합계 리스트\n","        topic_sum_ls = []\n","        for j in range(len(self.doc_ls)) :\n","            temp_sum = 0\n","            for i in range(self.topic_num) :\n","                temp_sum += topic_dist_matrix_doc[i][j]\n","            topic_sum_ls.append(temp_sum)\n","\n","        # 문서 내에 토픽이 있을 확률을 나타내는 새로운 매트릭스 생성\n","        topic_in_doc_matrix = np.zeros((self.topic_num, len(self.doc_ls)))\n","\n","        for i in range(self.topic_num) :\n","            for j in range(len(self.doc_ls)) :\n","                topic_in_doc_matrix[i][j] = topic_dist_matrix_doc[i][j]/topic_sum_ls[j]\n","        \n","        return topic_in_doc_matrix\n","    \n","    def mk_word_in_topic_matrix(self, word2idx, topic_dist_matrix_word) :\n","        word_in_topic_matrix = np.zeros((self.topic_num, len(word2idx)))\n","\n","        # topic 내의 단어가 cute일 확률\n","        for idx, topic in enumerate(topic_dist_matrix_word) :\n","            for idx2, topic_word in enumerate(topic) :\n","                word_in_topic_matrix[idx][idx2] = topic_word/sum(topic)\n","        return word_in_topic_matrix\n","\n","    def mk_topic_distribution_ls(self, topic_ls, topic_in_doc_matrix, word_in_topic_matrix, topic_dist_matrix_word) :\n","\n","        #문서 내 토픽 분포 리스트 초기화\n","        topic_distribution_ls = [[0 for x in range(len(topic_ls[i]))] for i in range(len(topic_ls))]\n","\n","        #문서 안의 특정 단어가 토픽 1일 확률\n","        #doc_ls a문서의 첫번째 단어가 토픽 1일 확률, 토픽 2일 확률을 비교해 큰값 doc_ls 형태에 반영\n","\n","        compare_list = [] \n","        for idx, doc in enumerate(self.doc_ls) : #문서 인덱스 가져오기\n","            for idx2, word_topic in enumerate(doc) :\n","                temp_list = []\n","                for i in range(self.topic_num) :\n","                    temp_list.append(topic_in_doc_matrix[i][idx] * word_in_topic_matrix[i][word2idx[doc_ls[idx][idx2]]])   #토픽 1일 확률과 토픽 2일 확률 비교\n","                compare_list.append(temp_list)\n","\n","                # compare_list[idx].argsort()\n","                topic_distribution_ls[idx][idx2] = np.array(compare_list[idx]).argsort()[0] + 1 # topic 분류를 위해 1 더함\n","\n","        # print(compare_list)\n","        # print()\n","        # print(topic_distribution_ls)\n","        return topic_distribution_ls\n","\n","    def mk_random_topic_ls(self):\n","        topic_ls = []\n","\n","        for doc_idx in range(len(self.doc_ls)) :\n","            temp_ls = []\n","            for i in range(len(self.doc_ls[doc_idx])):\n","                temp_ls.append(random.randint(1, self.topic_num))\n","            topic_ls.append(temp_ls)\n","\n","        return topic_ls\n","\n","    def mk_final_topic_ls(self, topic_ls, word2idx) :\n","        for x in range(100) :\n","            temp_topic_ls = topic_ls\n","\n","            topic_dist_matrix_doc = self.mk_topic_dist_matrix(topic_ls)\n","            topic_dist_matrix_word = self.mk_topic_dist_matrix_word(topic_ls, word2idx)\n","            topic_in_doc_matrix = self.chance_topic_in_doc(topic_dist_matrix_doc)\n","            word_in_topic_matrix = self.mk_word_in_topic_matrix(word2idx, topic_dist_matrix_word)\n","            topic_ls = self.mk_topic_distribution_ls(topic_ls,topic_in_doc_matrix, word_in_topic_matrix,topic_dist_matrix_word)\n","\n","            # print(topic_ls)\n","            if temp_topic_ls == topic_ls :\n","                break\n","        print('최종 분류 토픽 : {}'.format(topic_ls))\n","        return topic_ls\n","    \n","    def topic_modeling(self, topic_ls, word2idx, idex2word) :\n","        for idx, topic in enumerate(word_in_topic_matrix) :\n","            print(\"Topic {}\".format(idx+1), end = ' : ')\n","            for i in range(len(word2idx)) :\n","                temp_idx = topic.argsort()[::-1][i]\n","                print(idex2word[temp_idx], topic[temp_idx].round(4),end = ', ')\n","            print()\n","        \n"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"08deDPDlrI_x","colab_type":"text"},"source":["###LDA클래스 실행"]},{"cell_type":"code","metadata":{"id":"WWxqw31cSb6E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1596681529771,"user_tz":-540,"elapsed":860,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}},"outputId":"742f4fea-8d06-4394-96b2-068f3e54183b"},"source":["test = LDA(3,doc_ls)\n","topic_ls = test.mk_random_topic_ls()\n","print(\"랜덤 토픽 할당 : {}\".format(topic_ls))\n","topic_ls = test.mk_final_topic_ls(topic_ls,word2idx)\n","\n","\n","test.topic_modeling(topic_ls,word2idx,idex2word)\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["랜덤 토픽 할당 : [[1, 3], [2, 2, 2], [2, 3], [1, 3], [1, 3, 1], [3, 2, 3, 2, 3]]\n","최종 분류 토픽 : [[3, 3], [1, 1, 1], [2, 2], [2, 2], [2, 2, 2], [1, 1, 1, 1, 1]]\n","Topic 1 : bread 0.2856, eat 0.2856, cake 0.1429, kitty 0.1429, cute 0.1429, hamster 0.0001, rice 0.0001, \n","Topic 2 : hamster 0.2, cake 0.2, rice 0.2, bread 0.1, eat 0.1, kitty 0.1, cute 0.1, \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"znGD8ITVKqdC","colab_type":"text"},"source":["###To_Do_fix :\n","1. 단어마다 토픽 재 할당 해줄때, 이미 해당 단어의 토픽 제외\n","2. 토픽 할당 시 결과값 진동 "]},{"cell_type":"code","metadata":{"id":"8KiasLQxavN3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596681402483,"user_tz":-540,"elapsed":3168,"user":{"displayName":"배진우","photoUrl":"","userId":"13417365113839528176"}}},"source":[""],"execution_count":null,"outputs":[]}]}